{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0QdVhSqGmWp"
   },
   "source": [
    "\n",
    "# Principal Componenet Analysis (PCA)\n",
    "The PCA algorithm is a dimensionality reduction algorithm which works really well for datasets which have correlated columns. It combines the features of X in linear combination such that the new components capture the most information of the data. \n",
    "\n",
    "The PCA model is implemented in the cuML library and can accept the following parameters: \n",
    "1. `svd_solver`: selects the type of algorithm used: Jacobi or full (default = full)\n",
    "2. `n_components`: the number of top K vectors to be present in the output (default = 1)\n",
    "3. `random_state`: select a random state if the results should be reproducible across multiple runs (default = None)\n",
    "4. `copy`: if 'True' then it copies the data and removes mean from it else the data will be overwritten with its mean centered version (default = True)\n",
    "5. `whiten`: if True, de-correlates the components (default = False)\n",
    "6. `tol`: if the svd_solver = 'Jacobi' then this variable is used to set the tolerance (default = 1e-7)\n",
    "7. `iterated_power`: if the svd_solver = 'Jacobi' then this variable decides the number of iterations (default = 15)\n",
    "\n",
    "The cuml implementation of the PCA model has the following functions that one can run:\n",
    "1. `Fit`: it fits the model with the dataset\n",
    "2. `Fit_transform`: fits the PCA model with the dataset and performs dimensionality reduction on it\n",
    "3. `Inverse_transform`: returns the original dataset when the transformed dataset is passed as the input\n",
    "4. `Transform`: performs dimensionality reduction on the dataset\n",
    "5. `Get_params`: returns the value of the parameters of the PCA model\n",
    "6. `Set_params`: allows the user to set the value of the parameters of the PCA model\n",
    "\n",
    "The model accepts only numpy arrays or cudf dataframes as the input. \n",
    "  - To convert your dataset to cudf format please read the cudf [documentation](https://rapidsai.github.io/projects/cudf/en/latest/)\n",
    "  - For additional information on the PCA model please refer to the [documentation](https://rapidsai.github.io/projects/cuml/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pOExsbY0Hzj6",
    "outputId": "fee7f582-ca44-40b6-8e38-db616deed881"
   },
   "outputs": [],
   "source": [
    "!wget -nc https://github.com/rapidsai/notebooks-extended/raw/master/utils/rapids-colab.sh\n",
    "!bash rapids-colab.sh\n",
    "\n",
    "import sys, os\n",
    "\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
    "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMYqyW55GmWq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA as skPCA\n",
    "from cuml import PCA as cumlPCA\n",
    "import cudf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "pxR0jcYfm4Ap",
    "outputId": "7af334b0-1519-4f7a-ed98-6b64f505cddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-27 09:54:22--  https://github.com/rapidsai/notebooks/blob/branch-0.8/cuml/data/mortgage.npy.gz?raw=true\n",
      "Resolving github.com (github.com)... 52.192.72.89\n",
      "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/rapidsai/notebooks/raw/branch-0.8/cuml/data/mortgage.npy.gz [following]\n",
      "--2019-07-27 09:54:22--  https://github.com/rapidsai/notebooks/raw/branch-0.8/cuml/data/mortgage.npy.gz\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/rapidsai/notebooks/branch-0.8/cuml/data/mortgage.npy.gz [following]\n",
      "--2019-07-27 09:54:23--  https://raw.githubusercontent.com/rapidsai/notebooks/branch-0.8/cuml/data/mortgage.npy.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6642646 (6.3M) [application/octet-stream]\n",
      "Saving to: ‘data/mortgage.npy.gz’\n",
      "\n",
      "data/mortgage.npy.g 100%[===================>]   6.33M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2019-07-27 09:54:23 (150 MB/s) - ‘data/mortgage.npy.gz’ saved [6642646/6642646]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/rapidsai/notebooks/blob/branch-0.8/cuml/data/mortgage.npy.gz?raw=true\n",
    "!mkdir -p data/ && wget -O data/mortgage.npy.gz https://github.com/rapidsai/notebooks/blob/branch-0.8/cuml/data/mortgage.npy.gz?raw=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OjRzSoiGmWt"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSSvVhfXGmWu"
   },
   "outputs": [],
   "source": [
    "# check if the mortgage dataset is present and then extract the data from it, else do not run \n",
    "import gzip\n",
    "def load_data(nrows, ncols, cached = 'data/mortgage.npy.gz'):\n",
    "    if os.path.exists(cached):\n",
    "        print('use mortgage data')\n",
    "        with gzip.open(cached) as f:\n",
    "            X = np.load(f)\n",
    "        X = X[np.random.randint(0,X.shape[0]-1,nrows),:ncols]\n",
    "    else:\n",
    "        # throws FileNotFoundError error if mortgage dataset is not present\n",
    "        raise FileNotFoundError('Please download the required dataset or check the path')\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i] for i in range(X.shape[1])})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlMQrDAuGmWw"
   },
   "outputs": [],
   "source": [
    "# this function checks if the results obtained from two different methods (sklearn and cuml) are the equal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def array_equal(a,b,threshold=2e-3,with_sign=True):\n",
    "    a = to_nparray(a)\n",
    "    b = to_nparray(b)\n",
    "    if with_sign == False:\n",
    "        a,b = np.abs(a),np.abs(b)\n",
    "    error = mean_squared_error(a,b)\n",
    "    res = error<threshold\n",
    "    return res\n",
    "\n",
    "# the function converts a variable from ndarray or dataframe format to numpy array\n",
    "def to_nparray(x):\n",
    "    if isinstance(x,np.ndarray) or isinstance(x,pd.DataFrame):\n",
    "        return np.array(x)\n",
    "    elif isinstance(x,np.float64):\n",
    "        return np.array([x])\n",
    "    elif isinstance(x,cudf.DataFrame) or isinstance(x,cudf.Series):\n",
    "        return x.to_pandas().values\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEt3pDA3GmW0"
   },
   "source": [
    "# Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fV3RsXIYGmW0",
    "outputId": "77b9ca3d-47e7-41ca-a0f0-68ae950a3eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use mortgage data\n",
      "CPU times: user 5.26 s, sys: 976 ms, total: 6.24 s\n",
      "Wall time: 6.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# nrows = number of samples\n",
    "# ncols = number of features of each sample\n",
    "\n",
    "nrows = 2**15\n",
    "nrows = int(nrows * 1.5)\n",
    "ncols = 400\n",
    "\n",
    "X = load_data(nrows,ncols)\n",
    "#print('data',X.shape) <- this line currently throws an error, tuple takes no attribute shape\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCh6JGajGmW3"
   },
   "outputs": [],
   "source": [
    "# set parameters for the PCA model\n",
    "n_components = 10\n",
    "whiten = False\n",
    "random_state = 42\n",
    "svd_solver=\"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "djvCwlRXGmW-",
    "outputId": "3fcbe6c0-9c4b-4b85-bc2e-069d05b6ec2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 s, sys: 498 ms, total: 1.8 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert the pandas dataframe to cudf dataframe\n",
    "X = cudf.DataFrame.from_pandas(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zKiCxgO8GmW6",
    "outputId": "e1da4c64-d660-4ef4-fb45-d4ab933ac354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 s, sys: 186 ms, total: 3.25 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use the sklearn PCA on the dataset\n",
    "pca_sk = skPCA(n_components=n_components,svd_solver=svd_solver, \n",
    "            whiten=whiten, random_state=random_state)\n",
    "# creates adwdwn embedding\n",
    "result_sk = pca_sk.fit_transform(to_nparray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UOqYo1yVGmXA",
    "outputId": "d87881da-f2de-429b-e6cb-46c81e4cc354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 107 ms, total: 1.32 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use the cuml PCA model on the dataset\n",
    "pca_cuml = cumlPCA(n_components=n_components,svd_solver=svd_solver, \n",
    "            whiten=whiten, random_state=random_state)\n",
    "# obtain the embedding of the model\n",
    "result_cuml = pca_cuml.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "rRJMM6P5GmXE",
    "outputId": "96df01c1-fffb-4b3b-e05a-49936a1c6253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare pca: cuml vs sklearn          singular_values_ equal\n",
      "compare pca: cuml vs sklearn               components_ equal\n",
      "compare pca: cuml vs sklearn       explained_variance_ equal\n",
      "compare pca: cuml vs sklearn explained_variance_ratio_ equal\n"
     ]
    }
   ],
   "source": [
    "# calculate the attributes of the two models and compare them\n",
    "for attr in ['singular_values_','components_','explained_variance_',\n",
    "             'explained_variance_ratio_']:\n",
    "    passed = array_equal(getattr(pca_sk,attr),getattr(pca_cuml,attr))\n",
    "    message = 'compare pca: cuml vs sklearn {:>25} {}'.format(attr,'equal' if passed else 'NOT equal')\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-o7f41eyGmXI",
    "outputId": "1861b100-9071-4738-eebb-e5e1022f9adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare pca: cuml vs sklearn transformed results equal\n"
     ]
    }
   ],
   "source": [
    "# compare the results of the two models\n",
    "passed = array_equal(result_sk,result_cuml)\n",
    "message = 'compare pca: cuml vs sklearn transformed results %s'%('equal'if passed else 'NOT equal')\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMZ9K3IDGmXM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pca_demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
